---
title: 'Review of Likelihoods'
author: "Drew Davison - STA 310: Homework 3"
output: pdf_document
---

```{r}
library(knitr)
library(magrittr)
library(kableExtra)
```

# Instructions

-   Write all narrative using full sentences. Write all interpretations and conclusions in the context of the data.
-   Be sure all analysis code is displayed in the rendered pdf.
-   If you are fitting a model, display the model output in a neatly formatted table. (The `tidy` and `kable` functions can help!)
-   If you are creating a plot, use clear and informative labels and titles.
-   Render and back up your work reguarly, such as using Github. 
-   When you're done, we should be able to render the final version of the Rmd document to fully reproduce your pdf.
- Upload your pdf to Gradescope. Upload your Rmd, pdf (and any data) to Canvas. 

# Exercises

## Exercise 1

Write out the likelihood for the Poisson distribution for $x_{1:n}.$

The probability mass function (PMF) of a Poisson-distributed random variable \( X \) with parameter \( \lambda \) is given by:

\[
P(X = x) = \frac{\lambda^x e^{-\lambda}}{x!}, \quad x = 0, 1, 2, \dots
\]

where \( \lambda > 0 \) is the rate parameter, which represents both the mean and variance of the distribution.

The likelihood function for the Poisson distribution, given a set of observations \( x_{1:n} = (x_1, x_2, \dots, x_n) \) from an i.i.d. sample, is the joint probability mass function:

\[
L(\lambda \mid x_{1:n}) = \prod_{i=1}^{n} P(X_i = x_i).
\]

Using the Poisson PMF:

\[
P(X_i = x_i) = \frac{\lambda^{x_i} e^{-\lambda}}{x_i!},
\]

the likelihood function is:

\[
L(\lambda \mid x_{1:n}) = \prod_{i=1}^{n} \frac{\lambda^{x_i} e^{-\lambda}}{x_i!}.
\]

Expanding the product:

\[
L(\lambda \mid x_{1:n}) = \frac{\lambda^{\sum_{i=1}^{n} x_i} e^{-n\lambda}}{\prod_{i=1}^{n} x_i!}.
\]

Thus, the likelihood function for \( x_{1:n} \) under a Poisson distribution with parameter \( \lambda \) is:

\[
L(\lambda \mid x_{1:n}) = \frac{\lambda^{\sum x_i} e^{-n\lambda}}{\prod x_i!}.
\]


## Exercise 2

Derive using calculus based methods the MLE of $\lambda$ is $\sum_i x_i/n$ (sample mean) and show that it is in fact a maximum. 

Given an i.i.d. sample \( x_1, x_2, \dots, x_n \) from a Poisson distribution with parameter \( \lambda \), the likelihood function is:

\[
L(\lambda \mid x_{1:n}) = \prod_{i=1}^{n} \frac{\lambda^{x_i} e^{-\lambda}}{x_i!}.
\]

Taking the log-likelihood function:

\[
\log L(\lambda) = \sum_{i=1}^{n} \log \left( \frac{\lambda^{x_i} e^{-\lambda}}{x_i!} \right).
\]

Expanding the summation:

\[
\log L(\lambda) = \sum_{i=1}^{n} \left[ x_i \log \lambda - \lambda - \log (x_i!) \right].
\]

Since the term \( \sum_{i=1}^{n} \log (x_i!) \) does not depend on \( \lambda \), it can be ignored in differentiation.

To find the MLE, we differentiate the log-likelihood with respect to \( \lambda \):

\[
\frac{d}{d\lambda} \log L(\lambda) = \sum_{i=1}^{n} \left[ \frac{x_i}{\lambda} - 1 \right].
\]

Setting this derivative equal to zero:

\[
\sum_{i=1}^{n} \left[ \frac{x_i}{\lambda} - 1 \right] = 0.
\]

Rearranging:

\[
\sum_{i=1}^{n} \frac{x_i}{\lambda} = n.
\]

\[
\frac{1}{\lambda} \sum_{i=1}^{n} x_i = n.
\]

Solving for \( \lambda \):

\[
\lambda = \frac{\sum_{i=1}^{n} x_i}{n}.
\]

Thus, the **MLE for** \( \lambda \) is:

\[
\hat{\lambda} = \bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i.
\]

To confirm that this is a **maximum**, we compute the second derivative:

\[
\frac{d^2}{d\lambda^2} \log L(\lambda) = \sum_{i=1}^{n} \left( -\frac{x_i}{\lambda^2} \right).
\]

Since \( x_i \) are non-negative, this sum is always **negative** for \( \lambda > 0 \), meaning that the function is **concave** at \( \hat{\lambda} \), confirming a **maximum**.

Thus, the **MLE** of \( \lambda \) is:

\[
\hat{\lambda} = \frac{\sum x_i}{n}
\]

which is the **sample mean**, and it is indeed a **maximum**.


## Exercise 3 

Verify using a grid-search that your solution matches to the calculus based one, where you may assume for simplicity that $\sum_i x_i = 500.$ You may assume 100 observations. (Hint: show that the approximated MLE is 5.)

## Exercise 4 (Derived from Chapter 2 of BMLR).

**The hot hand in basketball.**  @Gilovich1985 wrote a controversial but compelling article claiming that there is no such thing as “the hot hand” in basketball.  That is, there is no empirical evidence that shooters have stretches where they are more likely to make consecutive shots, and basketball shots are essentially independent events.  One of the many ways they tested for evidence of a “hot hand” was to record sequences of shots for players under game conditions and determine if players are more likely to make shots after made baskets than after misses.  For instance, assume we recorded data from one player's first 5 three-point attempts over a 5-game period.  We can assume games are independent, but we’ll consider two models for shots within a game:

- No Hot Hand (1 parameter): $p_B$ = probability of making a basket (thus $1-p_B$ = probability of not making a basket).

- Hot Hand (2 parameters): $p_B$ = probability of making a basket after a miss (or the first shot of a game); $p_{B|B}$ = probability of making a basket after making the previous shot.

a. Fill out Table \@ref(tab:hothandchp2)---write out the contribution of each game to the likelihood for both models along with the total likelihood for each model.

b. Given that, for the No Hot Hand model, $\textrm{Lik}(p_B)=p_B^{10}(1-p_B)^{15}$ for the 5 games where we collected data, how do we know that 0.40 (the maximum likelihood estimator (MLE) of $p_B$) is a better estimate than, say, 0.30?

c. Find the MLEs for the parameters in each model, and then use those MLEs to determine if there's significant evidence that the hot hand exists using a likelihood ratio test (LRT). Be sure to specify the test and provide all details of your approach, including reproducible code used. 

| Game | First five shots  | Likelihood (no hot hand) | Likelihood (hot hand)
|--------|-----------------|--------------------------|-----------------------|
| 1      | BMMBB            |                         |                       |
| 2      | MBMBM            |                         |                       |
| 3      | MMBBB            |                         |                       |
| 4      | BMMMB            |                         |                       |
| 5      | MMMMM            |                         |                       |




# Grading

| **Total**             | **15** |
|-----------------------|:------:|
| Ex 1                  |   2    |
| Ex 2                  |   5    |
| Ex 3                  |   5    |
| Ex 4                  |   8    |
| Workflow & formatting |   3    |

The "Workflow & formatting" grade is to based on the organization of the assignment write up along with the reproducible workflow. This includes having an organized write up with neat and readable headers, code, and narrative, including properly rendered mathematical notation. It also includes having a reproducible Rmd or Quarto document that can be rendered to reproduce the submitted PDF.
